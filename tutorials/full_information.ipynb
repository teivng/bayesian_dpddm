{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f13bc313470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/fs01/home/sidarya/PDDM_MEGA/bayesian_dpddm')\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEED = 9927\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/h/sidarya/.conda/envs/bayesian_pddm/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_utils import UCIDataset\n",
    "data_dict = torch.load('data/uci_data/uci_heart_torch.pt')\n",
    "uci_dict = {}\n",
    "for k, data in data_dict.items():\n",
    "    data = list(zip(*data))\n",
    "    X, y = torch.stack(data[0]), torch.tensor(data[1], dtype=torch.int)\n",
    "    \n",
    "    # normalize\n",
    "    min_ = torch.min(X, dim=0).values\n",
    "    max_ = torch.max(X, dim=0).values\n",
    "    X = (X - min_) / (max_ - min_)\n",
    "    uci_dict[k] = UCIDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {}\n",
    "dataset_dict['train'] = uci_dict['train']\n",
    "dataset_dict['valid'] = uci_dict['val']\n",
    "dataset_dict['dpddm_train'] = uci_dict['val']\n",
    "dataset_dict['dpddm_id'] = uci_dict['iid_test']\n",
    "dataset_dict['dpddm_ood'] = uci_dict['ood_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from bayesian_dpddm import MLPModel, DPDDMBayesianMonitor, DPDDMFullInformationMoniter\n",
    "from bayesian_dpddm.monitors import DPDDMFullInformationMoniter\n",
    "from experiments.utils import get_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize(config_path='./PDDM_MEGA/bayesian_dpddm/experiments/configs', version_base='1.2')\n",
    "args = hydra.compose(config_name=\"uci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config, train_config = get_configs(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "base_model = MLPModel(model_config, train_size=len(dataset_dict['train']))\n",
    "\n",
    "monitor = DPDDMFullInformationMoniter(\n",
    "    model=base_model,\n",
    "    trainset=dataset_dict['train'],\n",
    "    valset=dataset_dict['valid'],\n",
    "    train_cfg=train_config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:43,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0, train loss: 0.6346\n",
      "Epoch:  0, valid loss: 0.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:09<00:34,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, train loss: 0.4854\n",
      "Epoch: 10, valid loss: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:18<00:25,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, train loss: 0.4782\n",
      "Epoch: 20, valid loss: 0.4483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:27<00:16,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, train loss: 0.4414\n",
      "Epoch: 30, valid loss: 0.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:36<00:08,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, train loss: 0.4801\n",
      "Epoch: 40, valid loss: 0.4311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:44<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "output_metrics = monitor.train_model(tqdm_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.561814695596695),\n",
       " np.float64(0.7446546057860056),\n",
       " np.float64(0.765213817358017),\n",
       " np.float64(0.773026317358017),\n",
       " np.float64(0.7754934231440226),\n",
       " np.float64(0.757538378238678),\n",
       " np.float64(0.7606907884279887),\n",
       " np.float64(0.7635690768559774),\n",
       " np.float64(0.7705592115720113),\n",
       " np.float64(0.804413378238678),\n",
       " np.float64(0.7876918911933899),\n",
       " np.float64(0.8079769710699717),\n",
       " np.float64(0.7668585578600565),\n",
       " np.float64(0.7841282884279887),\n",
       " np.float64(0.789610743522644),\n",
       " np.float64(0.7913925449053446),\n",
       " np.float64(0.788788378238678),\n",
       " np.float64(0.7982456187407175),\n",
       " np.float64(0.7720668911933899),\n",
       " np.float64(0.797423243522644),\n",
       " np.float64(0.7982456187407175),\n",
       " np.float64(0.8071546057860056),\n",
       " np.float64(0.8078399101893107),\n",
       " np.float64(0.8087993462880453),\n",
       " np.float64(0.7948190768559774),\n",
       " np.float64(0.8078399101893107),\n",
       " np.float64(0.781661182641983),\n",
       " np.float64(0.7824835578600565),\n",
       " np.float64(0.7868695159753164),\n",
       " np.float64(0.8060581187407175),\n",
       " np.float64(0.8016721506913503),\n",
       " np.float64(0.797423243522644),\n",
       " np.float64(0.8086622854073843),\n",
       " np.float64(0.7834429840246836),\n",
       " np.float64(0.7956414520740509),\n",
       " np.float64(0.7860471506913503),\n",
       " np.float64(0.780838817358017),\n",
       " np.float64(0.7937225898106893),\n",
       " np.float64(0.813185304403305),\n",
       " np.float64(0.8007127245267233),\n",
       " np.float64(0.8183936377366384),\n",
       " np.float64(0.8061951796213785),\n",
       " np.float64(0.8018092115720113),\n",
       " np.float64(0.7990679840246836),\n",
       " np.float64(0.7746710578600565),\n",
       " np.float64(0.8034539520740509),\n",
       " np.float64(0.7981085578600565),\n",
       " np.float64(0.8218201796213785),\n",
       " np.float64(0.7878289520740509),\n",
       " np.float64(0.8060581187407175)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monitor.output_metrics[\"train_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:51<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "monitor.pretrain_disagreement_distribution(dataset=dataset_dict['dpddm_train'],\n",
    "                                           n_post_samples=args.dpddm.n_post_samples,\n",
    "                                           data_sample_size=args.dpddm.data_sample_size,\n",
    "                                           Phi_size=args.dpddm.Phi_size, \n",
    "                                           temperature=args.dpddm.temp,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:09<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_train: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:09<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_id: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:10<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpddm_ood: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "dis_rates = {}\n",
    "\n",
    "for k,dataset in {\n",
    "    'dpddm_train': dataset_dict['dpddm_train'],\n",
    "    'dpddm_id': dataset_dict['dpddm_id'],\n",
    "    'dpddm_ood': dataset_dict['dpddm_ood']\n",
    "}.items():\n",
    "    rate, max_dis_rates = monitor.repeat_tests(n_repeats=args.dpddm.n_repeats,\n",
    "                                    dataset=dataset, \n",
    "                                    n_post_samples=args.dpddm.n_post_samples,\n",
    "                                    data_sample_size=args.dpddm.data_sample_size,\n",
    "                                    temperature=args.dpddm.temp\n",
    "                                    )\n",
    "    print(f\"{k}: {rate}\")\n",
    "    stats[k] = rate\n",
    "    dis_rates[k] = (np.mean(max_dis_rates), np.std(max_dis_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bayesian PDDM",
   "language": "python",
   "name": "bayesian_pddm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
