{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import wilds\n",
    "print(wilds.__version__)\n",
    "from wilds.datasets.camelyon17_dataset import Camelyon17Dataset\n",
    "from wilds.datasets.civilcomments_dataset import CivilCommentsDataset\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camelyon17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Camelyon17Dataset(root_dir='/voyager/datasets', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" For Bayesian D-PDDM\n",
    "- train         (used to train base model)\n",
    "- valid         (used ot validate base model)\n",
    "- dpddm_train   (used to train dpddm's Phi)\n",
    "- dpddm_id      (used to validate FPR)\n",
    "- dpddm_ood     (used to validate TPR)\n",
    "\"\"\"\n",
    "\n",
    "splits = {\n",
    "    'train': 'train',\n",
    "    'valid': 'val',\n",
    "    'dpddm_train': 'id_val',\n",
    "    'dpddm_id': 'val',\n",
    "    'dpddm_ood': 'test'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 302436\n",
      "valid 34904\n",
      "dpddm_train 33560\n",
      "dpddm_id 34904\n",
      "dpddm_ood 85054\n"
     ]
    }
   ],
   "source": [
    "for split in splits.keys():\n",
    "    try: \n",
    "        ds = dataset.get_subset(splits[split], transform=Compose([Resize((224, 224)), ToTensor()]))\n",
    "        print(split, len(ds))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.get_subset(splits['train'], transform=Compose([Resize((224, 224)), ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>▁▆█</td></tr><tr><td>train_loss</td><td>█▃▁</td></tr><tr><td>val_acc</td><td>▃█▁</td></tr><tr><td>val_loss</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_acc</td><td>94.67332</td></tr><tr><td>train_loss</td><td>0.14796</td></tr><tr><td>val_acc</td><td>77.47851</td></tr><tr><td>val_loss</td><td>0.93549</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-brook-25</strong> at: <a href='https://wandb.ai/opent03-team/wilds_dpddm/runs/0l3vze4w' target=\"_blank\">https://wandb.ai/opent03-team/wilds_dpddm/runs/0l3vze4w</a><br> View project at: <a href='https://wandb.ai/opent03-team/wilds_dpddm' target=\"_blank\">https://wandb.ai/opent03-team/wilds_dpddm</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250411_054405-0l3vze4w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/h/300/viet/bayesian_dpddm/wandb/run-20250411_054729-5rjbw6u7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/opent03-team/wilds_dpddm/runs/5rjbw6u7' target=\"_blank\">rosy-frog-26</a></strong> to <a href='https://wandb.ai/opent03-team/wilds_dpddm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/opent03-team/wilds_dpddm' target=\"_blank\">https://wandb.ai/opent03-team/wilds_dpddm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/opent03-team/wilds_dpddm/runs/5rjbw6u7' target=\"_blank\">https://wandb.ai/opent03-team/wilds_dpddm/runs/5rjbw6u7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/300/viet/.conda/envs/dpddm_tmp/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/h/300/viet/.conda/envs/dpddm_tmp/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:41<00:00, 22.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.3420, Train Acc: 86.40%, Val Loss: 0.4509, Val Acc: 82.87%\n",
      "Test Accuracy: 85.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|█████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:40<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.2180, Train Acc: 91.75%, Val Loss: 0.4549, Val Acc: 87.22%\n",
      "Test Accuracy: 88.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|█████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:39<00:00, 23.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.1801, Train Acc: 93.30%, Val Loss: 0.5520, Val Acc: 83.98%\n",
      "Test Accuracy: 75.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|█████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:40<00:00, 23.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.1697, Train Acc: 93.62%, Val Loss: 0.3734, Val Acc: 88.02%\n",
      "Test Accuracy: 80.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|█████████████████████████████████████████████████████████████████████████████████████| 946/946 [00:40<00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.1589, Train Acc: 94.12%, Val Loss: 0.3795, Val Acc: 87.85%\n",
      "Test Accuracy: 83.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   5%|███▉                                                                                  | 43/946 [00:02<00:37, 23.82it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from wilds.datasets.camelyon17_dataset import Camelyon17Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import wandb \n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"opent03-team\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"wilds_dpddm\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"architecture\": \"resnet18\",\n",
    "        \"dataset\": \"Camelyon17\",\n",
    "        \"epochs\": 50,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize WILDS dataset\n",
    "dataset = Camelyon17Dataset(root_dir='/h/300/viet/bayesian_dpddm/data', download=True)\n",
    "\n",
    "# Get train, validation, and test sets\n",
    "train_data = dataset.get_subset('train', frac=0.1)\n",
    "val_data = dataset.get_subset('val',  frac=0.1)\n",
    "test_data = dataset.get_subset('test',  frac=0.1)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=90),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# For validation/test (no augmentations)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Apply transformations\n",
    "train_data.transform = train_transform\n",
    "val_data.transform = val_transform\n",
    "test_data.transform = val_transform\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Initialize ResNet18\n",
    "model = resnet50(pretrained=False)  # Using pretrained weights\n",
    "\n",
    "# Modify the final layer for binary classification (tumor vs normal)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Camelyon17 has 2 classes\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Training phase\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        x, y, metadata = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc\n",
    "    })\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x, y, metadata = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    wandb.log({\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc\n",
    "    })\n",
    "\n",
    "    # Test evaluation\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            x, y, metadata = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += y.size(0)\n",
    "            test_correct += (predicted == y).sum().item()\n",
    "            \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "    wandb.log({\n",
    "        'test_acc': test_acc\n",
    "    })\n",
    "    print(f'Test Accuracy: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CivilComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import wilds\n",
    "print(wilds.__version__)\n",
    "from wilds.datasets.civilcomments_dataset import CivilCommentsDataset\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir('/mfs1/u/viet/bayesian_dpddm')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mfs1/u/viet/bayesian_dpddm\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CivilCommentsDataset(root_dir=\"data/\", download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269038, 45180, 133782)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = dataset.get_subset('train')\n",
    "valset = dataset.get_subset('val')\n",
    "testset = dataset.get_subset('test')\n",
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7524ceaa94b495bb71b01085646f9f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b22de5473843a184b88d293e292144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b7bd1e6bb14ce88f8f4e0ef864029e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "i = 0\n",
    "for split in [trainset, valset, testset]:\n",
    "    meta = []\n",
    "    meta_labels = 0\n",
    "    for text, label, metadata in tqdm(split):\n",
    "        meta.append(metadata)\n",
    "        meta_labels += label\n",
    "    meta = torch.stack(meta, dim=0)\n",
    "    meta_labels = meta_labels / len(split)\n",
    "    sum_meta = torch.sum(meta, dim=0)/len(split)\n",
    "    ax[i].bar(range(15), sum_meta[:15])\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple\n",
    "def split_dataset(dataset: Dataset, lengths: list, random_seed: int = 57) -> Tuple[Dataset, Dataset]:\n",
    "    return random_split(dataset, lengths,\n",
    "                        generator=torch.Generator().manual_seed(random_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trainset, id_val1, id_val2 = split_dataset(trainset, [0.8, 0.1, 0.1], random_seed=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"This is a terrible comment.\",\n",
    "    \"Great insight, thanks for sharing!\"\n",
    "]\n",
    "\n",
    "# Tokenize with padding/truncation\n",
    "tokens = tokenizer(\n",
    "    texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 768])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(**tokens).last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bert_model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(new_trainset, 64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43732aa54d994fd793168b7d2e321abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/269038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m tqdm(trainset):\n\u001b[32m      4\u001b[39m     text = sample[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# assuming first item is the raw text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     tokens = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# works for HuggingFace tokenizers\u001b[39;00m\n\u001b[32m      6\u001b[39m     tokenized_samples.append(tokens)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2887\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.__call__\u001b[39m\u001b[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   2885\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._in_target_context_manager:\n\u001b[32m   2886\u001b[39m         \u001b[38;5;28mself\u001b[39m._switch_to_input_mode()\n\u001b[32m-> \u001b[39m\u001b[32m2887\u001b[39m     encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2888\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2889\u001b[39m     \u001b[38;5;28mself\u001b[39m._switch_to_target_mode()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2997\u001b[39m, in \u001b[36mPreTrainedTokenizerBase._call_one\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m   2975\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m   2976\u001b[39m         batch_text_or_text_pairs=batch_text_or_text_pairs,\n\u001b[32m   2977\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2994\u001b[39m         **kwargs,\n\u001b[32m   2995\u001b[39m     )\n\u001b[32m   2996\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3000\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3016\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3073\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m   3063\u001b[39m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m   3064\u001b[39m padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m   3065\u001b[39m     padding=padding,\n\u001b[32m   3066\u001b[39m     truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3070\u001b[39m     **kwargs,\n\u001b[32m   3071\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msplit_special_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:613\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._encode_plus\u001b[39m\u001b[34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[39m\n\u001b[32m    589\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_encode_plus\u001b[39m(\n\u001b[32m    590\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    591\u001b[39m     text: Union[TextInput, PreTokenizedInput],\n\u001b[32m   (...)\u001b[39m\u001b[32m    610\u001b[39m     **kwargs,\n\u001b[32m    611\u001b[39m ) -> BatchEncoding:\n\u001b[32m    612\u001b[39m     batched_input = [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     batched_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    635\u001b[39m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[32m    636\u001b[39m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/transformers/tokenization_utils_fast.py:539\u001b[39m, in \u001b[36mPreTrainedTokenizerFast._batch_encode_plus\u001b[39m\u001b[34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[39m\n\u001b[32m    536\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tokenizer.encode_special_tokens != split_special_tokens:\n\u001b[32m    537\u001b[39m     \u001b[38;5;28mself\u001b[39m._tokenizer.encode_special_tokens = split_special_tokens\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m encodings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[32m    551\u001b[39m tokens_and_encodings = [\n\u001b[32m    552\u001b[39m     \u001b[38;5;28mself\u001b[39m._convert_encoding(\n\u001b[32m    553\u001b[39m         encoding=encoding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    562\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[32m    563\u001b[39m ]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tokenized_samples = []\n",
    "\n",
    "for sample in tqdm(trainset):\n",
    "    text = sample[0]  # assuming first item is the raw text\n",
    "    tokens = tokenizer(text)  # works for HuggingFace tokenizers\n",
    "    tokenized_samples.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
