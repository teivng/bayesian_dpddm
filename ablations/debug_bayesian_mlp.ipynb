{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9f0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('../')\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import compose, initialize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ablations.models import BayesianMLP\n",
    "from experiments.utils import get_configs, get_datasets\n",
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df1a24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'disagreement_epochs': 5, 'disagreement_optimizer': 'torch.optim.AdamW', 'disagreement_wd': 0.0001, 'disagreement_lr': 0.01, 'disagreement_batch_size': 64, 'disagreement_alpha': 0.8, 'num_epochs': 50, 'batch_size': 64, 'lr': 0.001, 'wd': 0.0001, 'optimizer': 'torch.optim.AdamW', 'clip_val': 1, 'val_freq': 1, 'num_workers': 4, 'pin_memory': True}, 'dataset': {'name': 'uci', 'num_classes': 2, 'data_dir': 'data/uci_data', 'normalize': True}, 'dpddm': {'Phi_size': 1000, 'n_post_samples': 5000, 'data_sample_size': 10, 'temp': 1, 'n_repeats': 100}, 'model': {'name': 'mlp_model', 'in_features': 9, 'mid_features': 16, 'mid_layers': 4, 'dropout': 0.2, 'reg_weight_factor': 100, 'param': 'diagonal', 'prior_scale': 1.0, 'wishart_scale': 1.0, 'return_ood': False}, 'wandb_cfg': {'project': 'bayesian_dpddm', 'entity': 'viet', 'job_type': 'train', 'log_artifacts': True}, 'monitor_type': 'bayesian', 'from_pretrained': False, 'seed': 57, 'self_log': True}\n"
     ]
    }
   ],
   "source": [
    "# Point to your config directory and name\n",
    "config_dir = \"configs/\"  # adjust as needed\n",
    "config_name = \"uci_best.yaml\"\n",
    "\n",
    "with initialize(config_path=config_dir, version_base='1.2'):\n",
    "    args = compose(config_name=config_name)\n",
    "\n",
    "# cfg is now a DictConfig\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "510b4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_datasets(args)\n",
    "model_config, train_config = get_configs(args)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset['train'],\n",
    "    batch_size=train_config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=train_config.num_workers,\n",
    "    pin_memory=train_config.pin_memory,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    dataset['valid'],\n",
    "    batch_size=train_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_config.num_workers,\n",
    "    pin_memory=train_config.pin_memory,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "oodloader = torch.utils.data.DataLoader(\n",
    "    dataset['dpddm_ood'],\n",
    "    batch_size = train_config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=train_config.num_workers,\n",
    "    pin_memory=True, \n",
    "    persistent_workers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6ddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianMLP(model_config).cuda()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1485544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:01<00:00, 29.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(train_config.num_epochs)):\n",
    "    model.train()\n",
    "    for batch in tqdm(trainloader, leave=False):\n",
    "        features, labels, *_ = batch\n",
    "        features, labels = features.cuda(), labels.cuda()\n",
    "        out, kl = model(features)\n",
    "        loss = criterion(out, labels.long()) + kl / len(labels)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ff9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_preds, all_labels = [], []\n",
    "        for batch in loader:\n",
    "            features, labels, *_ = batch\n",
    "            features, labels = features.cuda(), labels.cuda()\n",
    "            output_mc = []\n",
    "            for mc_run in tqdm(range(1000), leave=False):\n",
    "                outputs, _ = model(features)\n",
    "                probs = torch.nn.functional.softmax(outputs, dim=-1)\n",
    "                output_mc.append(probs)\n",
    "            output = torch.stack(output_mc)  \n",
    "            pred_mean = output.mean(dim=0)\n",
    "            y_pred = torch.argmax(pred_mean, axis=-1)\n",
    "            all_preds.append(y_pred)\n",
    "            all_labels.append(labels)\n",
    "    all_preds, all_labels = list(map(lambda x: torch.concatenate(x, dim=0), [all_preds, all_labels]))\n",
    "    return (all_preds == all_labels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3294a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7933, device='cuda:0'),\n",
       " tensor(0.7667, device='cuda:0'),\n",
       " tensor(0.6440, device='cuda:0'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, trainloader), evaluate(model, valloader), evaluate(model, oodloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5da712c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_dataset(dataset, data_sample_size:int=100):\n",
    "    indices = torch.randint(0, len(dataset), (data_sample_size,))\n",
    "    return Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88243812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudolabels(model, X:torch.tensor, mc_samples=1000):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X = X.cuda()\n",
    "        out_mc = []\n",
    "        for mc_run in tqdm(range(mc_samples), leave=False):\n",
    "            out, _ = model(X)\n",
    "            out_mc.append(out)\n",
    "        output = torch.stack(out_mc)\n",
    "        pred_mean = output.mean(dim=0)\n",
    "        y_pred = torch.argmax(pred_mean, dim=-1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a96d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_dis_rate(model, X, y, n_post_samples=5000):\n",
    "    X, y = X.cuda(), y.cuda()\n",
    "    with torch.no_grad():\n",
    "        out_mc = []\n",
    "        for _ in tqdm(range(n_post_samples), leave=False):\n",
    "            out, _ = model(X)\n",
    "            out_mc.append(out)\n",
    "        output = torch.stack(out_mc)\n",
    "        y_tile = torch.tile(y, (n_post_samples, 1)).cuda()\n",
    "        \n",
    "        #dist = torch.distributions.Categorical(logits=output/5)\n",
    "        #y_hat = dist.sample()\n",
    "        y_hat = output.argmax(dim=-1)\n",
    "        dis_mat = (y_hat != y_tile)\n",
    "        dis_rate = dis_mat.float().mean(dim=-1)\n",
    "        return dis_rate.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0d47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Phi(model, dataset, *, n_post_samples, Phi_size, data_sample_size):\n",
    "    Phi = []\n",
    "    for i in tqdm(range(Phi_size)):\n",
    "        sbs = sample_from_dataset(dataset, data_sample_size)\n",
    "        pseudo = get_pseudolabels(model, sbs.dataset.X)\n",
    "        dis_rate = compute_max_dis_rate(model, sbs.dataset.X, pseudo, n_post_samples=n_post_samples)\n",
    "        #Phi.append(dis_rate)\n",
    "        print(dis_rate)\n",
    "        if i == 10:\n",
    "            break\n",
    "    return Phi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdc7281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:02<17:10,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [00:04<17:05,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550000011920929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:06<17:01,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5666667222976685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [00:07<20:59,  2.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m Phi = \u001b[43mget_Phi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdpddm_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m              \u001b[49m\u001b[43mn_post_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m              \u001b[49m\u001b[43mPhi_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m              \u001b[49m\u001b[43mdata_sample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_Phi\u001b[39m\u001b[34m(model, dataset, n_post_samples, Phi_size, data_sample_size)\u001b[39m\n\u001b[32m      4\u001b[39m sbs = sample_from_dataset(dataset, data_sample_size)\n\u001b[32m      5\u001b[39m pseudo = get_pseudolabels(model, sbs.dataset.X)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m dis_rate = \u001b[43mcompute_max_dis_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_post_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_post_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Phi.append(dis_rate)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(dis_rate)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcompute_max_dis_rate\u001b[39m\u001b[34m(model, X, y, n_post_samples)\u001b[39m\n\u001b[32m      4\u001b[39m out_mc = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_post_samples), leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     out, _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     out_mc.append(out)\n\u001b[32m      8\u001b[39m output = torch.stack(out_mc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/bayesian_dpddm/ablations/models/bayesian_mlp_model.py:32\u001b[39m, in \u001b[36mBayesianMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     31\u001b[39m     kl_sum = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     x, kl = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     kl_sum += kl\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_layer(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/bayesian_dpddm/ablations/models/bayesian_mlp_model.py:25\u001b[39m, in \u001b[36mBayesianMLP.get_features\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mid_fc:\n\u001b[32m     24\u001b[39m     identity = x\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     out, kl = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     kl_sum += kl\n\u001b[32m     27\u001b[39m     x = F.elu(out + identity)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mfs1/u/viet/.conda/envs/dpddm/lib/python3.11/site-packages/bayesian_torch/layers/variational_layers/linear_variational.py:172\u001b[39m, in \u001b[36mLinearReparameterization.forward\u001b[39m\u001b[34m(self, input, return_kl)\u001b[39m\n\u001b[32m    169\u001b[39m bias = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mu_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     sigma_bias = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog1p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrho_bias\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m     bias = \u001b[38;5;28mself\u001b[39m.mu_bias + (sigma_bias * \u001b[38;5;28mself\u001b[39m.eps_bias.data.normal_())\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_kl:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "Phi = get_Phi(model, dataset['dpddm_train'],\n",
    "              n_post_samples=500,\n",
    "              Phi_size=500,\n",
    "              data_sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d43cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:11<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "id = get_Phi(model, dataset['dpddm_id'], n_post_samples=500, Phi_size=100, data_sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5a09679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.07)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(lambda x: (x > np.quantile(Phi, 0.95)), id))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e01163e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:27<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "ood = get_Phi(model, dataset['dpddm_ood'], n_post_samples=500, Phi_size=100, data_sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "26cd39d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.88)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(lambda x: (x > np.quantile(Phi, 0.95)), ood))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795a8cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.3624166870713234), np.float64(0.017704951079720636))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Phi)\n",
    "np.mean(Phi), np.std(Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961267e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpddm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
